{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5053813-2c77-4e5e-886b-7d234e00fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3path import S3Path\n",
    "from getpass import getpass\n",
    "\n",
    "# S3 path to the S3 backup bucket, change to your bucket.\n",
    "base_path = S3Path(\"/bucket/some_prefix/your_export/\")\n",
    "# Connection string to the Postgres database, change to your database.\n",
    "postgres_con_string = \"postgresql+psycopg2://postgres:{ password }@localhost/postgres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc50856e-b36e-44ab-ad33-4d7b38dc17bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sql\n",
    "\n",
    "engine = sql.engine.create_engine(postgres_con_string.format(password=getpass()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20763e06-fd71-4022-8783-662f59684964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# The RDS export to S3 includes a JSON file with metadata about the export.\n",
    "# We  will use the file to get a list of tables. Change to your file.\n",
    "with (base_path / \"export_tables_info_your_export_from_1_to_XXX.json\").open() as f:\n",
    "    export_metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aa8d70-2420-4213-8cff-38337fcfc71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552d0fb1-b97e-492b-802e-7b44076ca8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class Table:\n",
    "    \"\"\"A table in the export.\n",
    "    \n",
    "    Attributes:\n",
    "        database: The database name.\n",
    "        schema: The schema name.\n",
    "        name: The table name.\n",
    "        output_schema: The schema name to use for the output.\n",
    "        output_name: The table name to use for the output.\n",
    "    \"\"\"\n",
    "    database: str\n",
    "    schema: str\n",
    "    name: str\n",
    "    output_schema: Optional[str] = None\n",
    "    output_name: Optional[str] = None\n",
    "\n",
    "    def get_S3_path(self, base_path: S3Path) -> S3Path:\n",
    "        return base_path / self.database / f\"{self.schema}.{self.name}\"\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a8d85-6756-4bca-af01-8c2ac03eb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [Table(*_.get(\"target\").split(\".\")) for _ in export_metadata.get(\"perTableStatus\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0411a14-af12-4154-917d-02729c354210",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c4b99-8507-42a9-a65b-13b0afc407a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_table_to_postgres(engine: sql.engine.Engine, table: Table):\n",
    "    \"\"\"Copy a selection of tables from S3 to a postgres instance.\n",
    "\n",
    "    params:\n",
    "        engine: SQLAlchemy Engine for the postgres instance\n",
    "        table: Table instance from the RDS-to-S3 back up catalog\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    name = table.output_name or table.name\n",
    "    schema = table.output_schema or table.schema\n",
    "    with engine.connect() as con:\n",
    "        if not engine.dialect.has_schema(con, schema):\n",
    "            con.execute(sql.schema.CreateSchema(schema, if_not_exists=True))\n",
    "            con.commit()\n",
    "    \n",
    "    for path in list(table.get_S3_path(base_path).rglob(\"*.parquet\")):\n",
    "        pd.read_parquet(path.as_uri()).to_sql(\n",
    "            name,\n",
    "            engine,\n",
    "            schema=schema,\n",
    "            if_exists=\"append\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d927fd45-9b8a-4c53-b763-5cdc9d4c5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def table_filter(tables: List[Table], matcher: str) -> List[Table]:\n",
    "    \"\"\"Filter a list of tables by a database/schema/table name.\n",
    "\n",
    "        params:\n",
    "            tables: List of Table instances from the RDS-to-S3 back up catalog\n",
    "            matcher: A string in the format of \"database.schema.table\" where\n",
    "                any of the parts can be replaced with \"*\" to match any value.\n",
    "\n",
    "        returns:\n",
    "            List of Table instances that match the matcher string.\n",
    "    \"\"\"\n",
    "    database, schema, name = matcher.split(\".\")\n",
    "\n",
    "    def _filter_(table: Table) -> bool:\n",
    "        if database == \"*\":\n",
    "            return True\n",
    "        elif table.database == database:\n",
    "            if schema == \"*\":\n",
    "                return True\n",
    "            elif table.schema == schema:\n",
    "                if name == \"*\" or table.name == name:\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    return list(filter(_filter_, tables))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62484920-d372-4b0a-a0a5-a233a4cef603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "def rename_mapper(table: Table, schema: Optional[str] = None, name: Optional[str] = None) -> Table:\n",
    "    \"\"\"Create a new Table instance with a new schema and/or name.\n",
    "\n",
    "        params:\n",
    "            table: Table instance from the RDS-to-S3 back up catalog\n",
    "            schema: New schema name, can include {database}, {schema}, and {name}\n",
    "            name: New table name, can include {database}, {schema}, and {name}\n",
    "\n",
    "        returns:\n",
    "            Table instance with the new schema and/or name.\n",
    "    \"\"\"\n",
    "\n",
    "    available_datafields = {\n",
    "        **asdict(table)\n",
    "    }\n",
    "\n",
    "    if schema:\n",
    "        table.output_schema = schema.format(**available_datafields)\n",
    "    if name:\n",
    "        table.output_name = name.format(**available_datafields)\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403684d-e8c0-4e88-a972-0e6e7f3bc018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "def copy_tables(tables: List[Table], matcher: str, engine: sql.engine.Engine, rename_map: Optional[Dict[str, str]] = None):\n",
    "    \"\"\"Copy a selection of tables from S3 to a postgres instance.\n",
    "    \n",
    "        params:\n",
    "            tables: List of Table instances from the RDS-to-S3 back up catalog\n",
    "            matcher: A string in the format of \"database.schema.table\" where\n",
    "                any of the parts can be replaced with \"*\" to match any value.\n",
    "            engine: SQLAlchemy Engine for the postgres instance\n",
    "            rename_map: A dictionary of new schema and/or table names. The values\n",
    "                should be in the format of \"some_new_prefix_{schema}\" where any of\n",
    "                the parts can be replaced with \"{database}\", \"{schema}\", and/or\n",
    "                \"{name}\" to use the original values from the table.\n",
    "    \"\"\"\n",
    "    table_list = list(table_filter(tables, matcher))\n",
    "    with tqdm(table_list) as pbar:\n",
    "        for table in table_list:\n",
    "            pbar.set_description(f\"Copying {table.schema}.{table.name}\")\n",
    "            copy_table_to_postgres(\n",
    "                engine,\n",
    "                rename_mapper(table, **rename_map) if rename_map else table\n",
    "            )\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37675df5-b3e3-40cd-a6e2-0b89655ea9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_tables(tables, \"notorious.twitter.*\", engine, {\"schema\": \"{database}_{schema}\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postgres-parquet-ingest",
   "language": "python",
   "name": "postgres-parquet-ingest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
